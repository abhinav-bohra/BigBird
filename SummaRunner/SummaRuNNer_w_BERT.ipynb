{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8vKgslrX0q"
      },
      "source": [
        "# SummaRuNNer with BERT on ECT\n",
        "## Usage\n",
        "Just run all the cells:-\n",
        "- Setup\n",
        "- Write Files\n",
        "    - RNN_RNN.py\n",
        "    - Vocab.py\n",
        "    - main.py\n",
        "- Training\n",
        "- Testing\n",
        "\n",
        "To change hyperparameters:\n",
        "- Edit main.py (3rd cell in Write Files)\n",
        "- Or specifiy as arguments in training cmd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjm2VA5I0BwG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tNWn-MCzfiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d0bef5-faed-490d-9a3f-112e722c5dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SummaRuNNer'...\n",
            "remote: Enumerating objects: 431, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 431 (delta 40), reused 39 (delta 39), pack-reused 385\u001b[K\n",
            "Receiving objects: 100% (431/431), 179.31 MiB | 13.70 MiB/s, done.\n",
            "Resolving deltas: 100% (222/222), done.\n",
            "Checking out files: 100% (27/27), done.\n",
            "Cloning into 'Long-Text-Summarization'...\n",
            "remote: Enumerating objects: 8148, done.\u001b[K\n",
            "remote: Counting objects: 100% (4006/4006), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3995/3995), done.\u001b[K\n",
            "remote: Total 8148 (delta 17), reused 3990 (delta 8), pack-reused 4142\u001b[K\n",
            "Receiving objects: 100% (8148/8148), 82.48 MiB | 11.23 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "Checking out files: 100% (11917/11917), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hpzhao/SummaRuNNer\n",
        "!git clone https://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@github.com/abhinav-bohra/Long-Text-Summarization.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHYQgSxSmmit",
        "outputId": "e8c94b4d-3a5e-4bc1-842d-6ed3ca5bbf18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SummaRuNNer\n"
          ]
        }
      ],
      "source": [
        "!cp /content/Long-Text-Summarization/data/reuters/summarunner/* /content/SummaRuNNer/data/\n",
        "%cd /content/SummaRuNNer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV6eaqzN0aIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7148fe53-f4a5-4450-e285-9e2f457bfe1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 31.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.4 MB/s \n",
            "\u001b[?25hCollecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers\n",
        "!pip install rouge\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-11p2-10DKw"
      },
      "source": [
        "## Write Files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abhinav"
      ],
      "metadata": {
        "id": "EqypsC2d1rQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRxwxbcarVpk",
        "outputId": "2ff97407-5100-4c2a-d43f-7a5ec703b93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/RNN_RNN.py\n"
          ]
        }
      ],
      "source": [
        "# SummaRuNNer with BERT models/RNN_RNN.py\n",
        "%%writefile models/RNN_RNN.py\n",
        "\n",
        "from .BasicModule import BasicModule\n",
        "import subprocess as sp\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"pytorch_pretrained_bert.tokenization\").setLevel(logging.ERROR)\n",
        "\n",
        "HH = 256\n",
        "\n",
        "class RNN_RNN(BasicModule):\n",
        "    def __init__(self, args, embed=None):\n",
        "        super(RNN_RNN, self).__init__(args)\n",
        "        self.model_name = 'RNN_RNN'\n",
        "        self.args = args\n",
        "\n",
        "        # V = args.embed_num\n",
        "        # D = args.embed_dim\n",
        "        H = args.hidden_size\n",
        "        S = args.seg_num\n",
        "        P_V = args.pos_num \n",
        "        P_D = args.pos_dim\n",
        "        self.abs_pos_embed = nn.Embedding(P_V,P_D)\n",
        "        self.rel_pos_embed = nn.Embedding(S,P_D)\n",
        "        # self.embed = nn.Embedding(V,D,padding_idx=0)\n",
        "        # if embed is not None:\n",
        "        #     self.embed.weight.data.copy_(embed)\n",
        "\n",
        "        self.bert_m = BertModel.from_pretrained('bert-base-cased',\n",
        "                                  ) \n",
        "        \n",
        "        for name, param in list(self.bert_m.named_parameters())[:-66]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.sent_RNN = nn.GRU(\n",
        "                        input_size = 768,\n",
        "                        hidden_size = HH,\n",
        "                        batch_first = True,\n",
        "                        bidirectional = True\n",
        "                        )\n",
        "        self.fc = nn.Linear(2*HH,2*HH)\n",
        "\n",
        "        # Parameters of Classification Layer\n",
        "        self.content = nn.Linear(2*HH,1,bias=False)\n",
        "        self.salience = nn.Bilinear(2*HH,2*HH,1,bias=False)\n",
        "        self.novelty = nn.Bilinear(2*HH,2*HH,1,bias=False)\n",
        "        self.abs_pos = nn.Linear(P_D,1,bias=False)\n",
        "        self.rel_pos = nn.Linear(P_D,1,bias=False)\n",
        "        self.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1,0.1))\n",
        "\n",
        "    def max_pool1d(self,x,seq_lens):\n",
        "        # x:[N,L,O_in]\n",
        "        out = []\n",
        "        for index,t in enumerate(x):\n",
        "            t = t[:seq_lens[index],:]\n",
        "            t = torch.t(t).unsqueeze(0)\n",
        "            out.append(F.max_pool1d(t,t.size(2)))\n",
        "\n",
        "        out = torch.cat(out).squeeze(2)\n",
        "        return out\n",
        "\n",
        "    def avg_pool1d(self,x,seq_lens):\n",
        "        # x:[N,L,O_in]\n",
        "        out = []\n",
        "        for index,t in enumerate(x):\n",
        "            t = t[:seq_lens[index],:]\n",
        "            t = torch.t(t).unsqueeze(0)\n",
        "            out.append(F.avg_pool1d(t,t.size(2)))\n",
        "\n",
        "        out = torch.cat(out).squeeze(2)\n",
        "        return out\n",
        "\n",
        "    def forward(self,input_ids,attention_masks,doc_lens):\n",
        "        # word level GRU\n",
        "        H = self.args.hidden_size\n",
        "        outputs = self.bert_m(input_ids=input_ids, attention_mask=attention_masks)\n",
        "        # hidden representation of last layer \n",
        "        token_vecs = outputs.last_hidden_state\n",
        "        # dimension : [N,max_len_sent,768] N: no of sentences\n",
        "        k=0\n",
        "        for i in token_vecs:\n",
        "            # cls embedding\n",
        "            sentence_embedding = i[0] \n",
        "            if(k==0): \n",
        "                sen = sentence_embedding.unsqueeze(0) \n",
        "                emb = sen\n",
        "                k=k+1\n",
        "            else:\n",
        "                sen = sentence_embedding.unsqueeze(0)\n",
        "                emb = torch.cat((emb,sen),0)\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        k=0\n",
        "        x = self.pad_doc(emb,doc_lens)\n",
        "        sent_out = self.sent_RNN(x)[0]\n",
        "        docs = self.max_pool1d(sent_out,doc_lens)\n",
        "        del emb\n",
        "        torch.cuda.empty_cache()\n",
        "        del input_ids\n",
        "        del attention_masks\n",
        "        torch.cuda.empty_cache()\n",
        "        probs = []\n",
        "        \n",
        "        for index,doc_len in enumerate(doc_lens):\n",
        "            valid_hidden = sent_out[index,:doc_len,:]                            # (doc_len,2*H)\n",
        "            doc = F.tanh(self.fc(docs[index])).unsqueeze(0)\n",
        "            s = Variable(torch.zeros(1,2*HH))\n",
        "            if self.args.device is not None:\n",
        "                s = s.cuda()\n",
        "            for position, h in enumerate(valid_hidden):\n",
        "                h = h.view(1, -1)                                                # (1,2*H)\n",
        "                # get position embeddings\n",
        "                abs_index = Variable(torch.LongTensor([[position]]))\n",
        "                if self.args.device is not None:\n",
        "                    abs_index = abs_index.cuda()\n",
        "                abs_features = self.abs_pos_embed(abs_index).squeeze(0)\n",
        "\n",
        "                rel_index = int(round((position + 1) * 9.0 / doc_len))\n",
        "                rel_index = Variable(torch.LongTensor([[rel_index]]))\n",
        "                if self.args.device is not None:\n",
        "                    rel_index = rel_index.cuda()\n",
        "                rel_features = self.rel_pos_embed(rel_index).squeeze(0)\n",
        "\n",
        "                # classification layer\n",
        "                content = self.content(h)\n",
        "                salience = self.salience(h,doc)\n",
        "                novelty = -1 * self.novelty(h,F.tanh(s))\n",
        "                abs_p = self.abs_pos(abs_features)\n",
        "                rel_p = self.rel_pos(rel_features)\n",
        "                prob = F.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n",
        "                s = s + torch.mm(prob,h)\n",
        "                probs.append(prob)\n",
        "        del sent_out\n",
        "        del docs\n",
        "        torch.cuda.empty_cache()\n",
        "        return torch.cat(probs).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds0SBEthpKyq",
        "outputId": "02f1bbe2-8e26-443d-8c83-cc0e9d3efb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils/Vocab.py\n"
          ]
        }
      ],
      "source": [
        "# SummaRuNNer with BERT utils/Vocab.py\n",
        "%%writefile utils/Vocab.py\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"pytorch_pretrained_bert.tokenization\").setLevel(logging.ERROR)\n",
        "\n",
        "class Vocab():\n",
        "    def __init__(self,embed,word2id):\n",
        "        self.embed = embed\n",
        "        self.word2id = word2id\n",
        "        # self.id2word = {v:k for k,v in word2id.items()}\n",
        "        # assert len(self.word2id) == len(self.id2word)\n",
        "        # self.PAD_IDX = 0\n",
        "        # self.UNK_IDX = 1\n",
        "        # self.PAD_TOKEN = 'PAD_TOKEN'\n",
        "        # self.UNK_TOKEN = 'UNK_TOKEN'\n",
        "\n",
        "    # def __len__(self):\n",
        "    #     return len(word2id)\n",
        "\n",
        "    # def i2w(self,idx):\n",
        "    #     return self.id2word[idx]\n",
        "    # def w2i(self,w):\n",
        "    #     if w in self.word2id:\n",
        "    #         return self.word2id[w]\n",
        "    #     else:\n",
        "    #         return self.UNK_IDX\n",
        "\n",
        "    def make_features(self,batch,sent_trunc=50,doc_trunc=800,split_token='\\n'):\n",
        "        sents_list,targets,doc_lens = [],[],[]\n",
        "        # trunc document\n",
        "        for doc,label in zip(batch['doc'],batch['labels']):\n",
        "            sents = doc.split(split_token)\n",
        "            labels = label.split(split_token)\n",
        "            try:\n",
        "                labels = [int(l) for l in labels]\n",
        "            except:\n",
        "                #print(\"Ignoring:\", labels, sents)\n",
        "                continue\n",
        "            max_sent_num = min(doc_trunc,len(sents))\n",
        "            sents = sents[:max_sent_num]\n",
        "            labels = labels[:max_sent_num]\n",
        "            sents_list += sents\n",
        "            targets += labels\n",
        "            doc_lens.append(len(sents))\n",
        "        # trunc or pad sent\n",
        "        max_sent_len = 0\n",
        "        batch_sents = []\n",
        "        for sent in sents_list:\n",
        "            words = sent.split()\n",
        "            if len(words) > sent_trunc:\n",
        "                words = words[:sent_trunc]\n",
        "            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
        "            batch_sents.append(words)\n",
        "\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "        for doc in batch['doc']:\n",
        "            doc_n = doc.split(split_token)\n",
        "            k=0\n",
        "            for sent in doc_n:\n",
        "                encoded_dict = tokenizer.encode_plus(\n",
        "                    sent,\n",
        "                    None,\n",
        "                    add_special_tokens=True,\n",
        "                    max_length=64,\n",
        "                    pad_to_max_length=True,\n",
        "                    return_token_type_ids=True,\n",
        "                    return_tensors=\"pt\"\n",
        "                    )\n",
        "                k=k+1\n",
        "                input_ids.append(encoded_dict['input_ids'])\n",
        "                attention_masks.append(encoded_dict['attention_mask'])\n",
        "                if(k==doc_trunc):\n",
        "                    break\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "        targets = torch.LongTensor(targets)\n",
        "        summaries = batch['summaries']\n",
        "\n",
        "        return input_ids,attention_masks,targets,summaries,doc_lens\n",
        "\n",
        "    def make_predict_features(self, batch, sent_trunc=150, doc_trunc=300, split_token='. '):\n",
        "        sents_list, doc_lens = [],[]\n",
        "        for doc in batch:\n",
        "            sents = doc.split(split_token)\n",
        "            max_sent_num = min(doc_trunc,len(sents))\n",
        "            sents = sents[:max_sent_num]\n",
        "            sents_list += sents\n",
        "            doc_lens.append(len(sents))\n",
        "\n",
        "        # trunc or pad sent\n",
        "        max_sent_len = 0\n",
        "        batch_sents = []\n",
        "        for sent in sents_list:\n",
        "            words = sent.split()\n",
        "            if len(words) > sent_trunc:\n",
        "                words = words[:sent_trunc]\n",
        "            max_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
        "            batch_sents.append(words)\n",
        "\n",
        "        # features = []\n",
        "        # for sent in batch_sents:\n",
        "        #     feature = [self.w2i(w) for w in sent] + [self.PAD_IDX for _ in range(max_sent_len-len(sent))]\n",
        "        #     features.append(feature)\n",
        "\n",
        "        #features = torch.LongTensor(features)\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "        for sent in sents_list:\n",
        "            encoded_dict = tokenizer.encode_plus(\n",
        "                    sent,                      # Sentence to encode.\n",
        "                    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                    max_length = 128,           # Pad & truncate all sentences.\n",
        "                    truncation = True,\n",
        "                    pad_to_max_length = True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                 )\n",
        "            input_ids.append(encoded_dict['input_ids'])\n",
        "            attention_masks.append(encoded_dict['attention_mask'])\n",
        "        input_ids = torch.cat(input_ids, dim=0)\n",
        "        attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "        return  input_ids,attention_masks,doc_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_nu4vizp7Vq",
        "outputId": "484f5bc9-cbe7-42da-906e-92663b8b0bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "# SummaRuNNer with BERT main.py\n",
        "%%writefile main.py\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import subprocess as sp\n",
        "import os\n",
        "import json\n",
        "import models\n",
        "import utils\n",
        "import argparse,random,logging,numpy,os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn.utils import clip_grad_norm\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"pytorch_pretrained_bert.tokenization\").setLevel(logging.ERROR)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [INFO] %(message)s')\n",
        "parser = argparse.ArgumentParser(description='extractive summary')\n",
        "# model\n",
        "parser.add_argument('-save_dir',type=str,default='checkpoints/')\n",
        "parser.add_argument('-embed_dim',type=int,default=100)\n",
        "parser.add_argument('-embed_num',type=int,default=100)\n",
        "parser.add_argument('-pos_dim',type=int,default=100)\n",
        "parser.add_argument('-pos_num',type=int,default=300)\n",
        "parser.add_argument('-seg_num',type=int,default=10)\n",
        "parser.add_argument('-kernel_num',type=int,default=100)\n",
        "parser.add_argument('-kernel_sizes',type=str,default='3,4,5')\n",
        "parser.add_argument('-model',type=str,default='RNN_RNN')\n",
        "parser.add_argument('-hidden_size',type=int,default=200)\n",
        "# train\n",
        "parser.add_argument('-lr',type=float,default=1e-5) #discuss\n",
        "parser.add_argument('-batch_size',type=int,default=32)\n",
        "parser.add_argument('-epochs',type=int,default=15)\n",
        "parser.add_argument('-seed',type=int,default=1)\n",
        "parser.add_argument('-train_dir',type=str,default='data/train.json')\n",
        "parser.add_argument('-val_dir',type=str,default='data/val.json')\n",
        "parser.add_argument('-embedding',type=str,default='data/embedding.npz')\n",
        "parser.add_argument('-word2id',type=str,default='data/word2id.json')\n",
        "parser.add_argument('-report_every',type=int,default=20)  #discuss 1350/8 = 168\n",
        "parser.add_argument('-seq_trunc',type=int,default=50) #discuss\n",
        "parser.add_argument('-max_norm',type=float,default=1.0) #discuss\n",
        "# test\n",
        "parser.add_argument('-load_dir',type=str,default='checkpoints/RNN_RNN_seed_1.pt')\n",
        "# parser.add_argument('-test_dir',type=str,default='data/val_ls_first100_without_scores.json')\n",
        "parser.add_argument('-test_dir',type=str,default='data/test.json')\n",
        "parser.add_argument('-ref',type=str,default='outputs/ref')\n",
        "parser.add_argument('-hyp',type=str,default='outputs/hyp')\n",
        "parser.add_argument('-filename',type=str,default='x.txt') # TextFile to be summarized\n",
        "parser.add_argument('-topk',type=int,default=8) #discuss\n",
        "# device\n",
        "parser.add_argument('-device',type=int)\n",
        "# option\n",
        "parser.add_argument('-test',action='store_true')\n",
        "parser.add_argument('-debug',action='store_true')\n",
        "parser.add_argument('-predict',action='store_true')\n",
        "args = parser.parse_args()\n",
        "use_gpu = args.device is not None\n",
        "\n",
        "if torch.cuda.is_available() and not use_gpu:\n",
        "\tprint(\"WARNING: You have a CUDA device, should run with -device 0\")\n",
        "\n",
        "# set cuda device and seed\n",
        "if use_gpu:\n",
        "\ttorch.cuda.set_device(args.device)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "numpy.random.seed(args.seed)\n",
        "\n",
        "\n",
        "def eval(net,vocab,data_iter,criterion):\n",
        "\twith torch.no_grad():\n",
        "\t\tnet.eval()\n",
        "\t\ttotal_loss = 0\n",
        "\t\tbatch_num = 0\n",
        "\t\tfor batch in data_iter:\n",
        "\t\t\tinput_ids,attention_masks,targets,_,doc_lens = vocab.make_features(batch)\n",
        "\t\t\tinput_ids,attention_masks,targets = Variable(input_ids),Variable(attention_masks), Variable(targets.float())\n",
        "\t\t\tif use_gpu:\n",
        "\t\t\t\ttargets = targets.cuda()\n",
        "\t\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\tprobs = net(input_ids,attention_masks,doc_lens)\n",
        "\t\t\tloss = criterion(probs,targets)\n",
        "\t\t\ttotal_loss += loss.item()\n",
        "\t\t\tbatch_num += 1\n",
        "\t\tloss = total_loss / batch_num\n",
        "\t\tdel targets\n",
        "\t\tdel input_ids\n",
        "\t\tdel attention_masks\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\t\tnet.train()\n",
        "\treturn loss\n",
        "\n",
        "def train():\n",
        "\tlogging.info('Loading vocab, train and val dataset. Wait a second, please')\n",
        "\tpp = 3\n",
        "\t# embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
        "\t# with open(args.word2id) as f:\n",
        "\t#     word2id = json.load(f)\n",
        "\tembed, word2id = None, None\n",
        "\tvocab = utils.Vocab(embed, word2id)    \n",
        "\n",
        "\twith open(args.train_dir) as f:\n",
        "\t\texamples = [json.loads(line) for line in f]\n",
        "\ttrain_dataset = utils.Dataset(examples)\n",
        "\n",
        "\twith open(args.val_dir) as f:\n",
        "\t\texamples = [json.loads(line) for line in f]\n",
        "\tval_dataset = utils.Dataset(examples)\n",
        "\n",
        "\t# update args\n",
        "\t# args.embed_num = embed.size(0)\n",
        "\t# args.embed_dim = embed.size(1)\n",
        "\targs.embed_num = None\n",
        "\targs.embed_dim = None\n",
        "\targs.kernel_sizes = [int(ks) for ks in args.kernel_sizes.split(',')]\n",
        "\n",
        "\tacc_steps = 16\n",
        "\t\n",
        "\t# build model\n",
        "\tnet = getattr(models,args.model)(args,embed)\n",
        "\tif use_gpu:\n",
        "\t\tnet.cuda()\n",
        "\t\n",
        "\t# load dataset\n",
        "\ttrain_iter = DataLoader(dataset=train_dataset,\n",
        "\t\t\tbatch_size=args.batch_size,\n",
        "\t\t\tshuffle=True)\n",
        "\tval_iter = DataLoader(dataset=val_dataset,\n",
        "\t\t\tbatch_size=args.batch_size,\n",
        "\t\t\tshuffle=False)\n",
        "\t\n",
        "\t# loss function\n",
        "\tcriterion = nn.BCELoss()\n",
        "\t\n",
        "\t# model info\n",
        "\t#print(net)\n",
        "\t\n",
        "\tparams = sum(p.numel() for p in list(net.parameters())) / 1e6\n",
        "\tprint('#Params: %.1fM' % (params))\n",
        "\n",
        "\tmin_loss = float('inf')\n",
        "\toptimizer = torch.optim.Adam(net.parameters(),lr=args.lr)\n",
        "\tnet.train()\n",
        "\n",
        "\tt1 = time()\n",
        "\tcheckpp = 0\n",
        "\tfor epoch in tqdm(range(1,args.epochs+1)):\n",
        "\t\tlogging.info(f\"\\nEpoch: {epoch}\")\n",
        "\t\tif(checkpp==pp):\n",
        "\t\t\tbreak\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tt_loss = 0\n",
        "\t\ts_loss = 0\n",
        "\t\tfor i,batch in enumerate(train_iter):\n",
        "\t\t\tinput_ids,attention_masks,targets,_,doc_lens = vocab.make_features(batch)\n",
        "\t\t\tinput_ids,attention_masks,targets = Variable(input_ids),Variable(attention_masks), Variable(targets.float())\n",
        "\t\t\tif use_gpu:\n",
        "\t\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\t   \n",
        "\t\t\tprobs = net(input_ids,attention_masks,doc_lens)\n",
        "\t\t\tif use_gpu:\n",
        "\t\t\t\ttargets = targets.cuda()\n",
        "\t\t   \n",
        "\t\t\tloss = criterion(probs,targets)\n",
        "\t\t\tt_loss = t_loss+loss.item()\n",
        "\t\t\tloss = loss / acc_steps\n",
        "\t\t\ts_loss = s_loss+1\n",
        "\t\t\tloss.backward()\n",
        "\t\t\tclip_grad_norm(net.parameters(), args.max_norm)\n",
        "\t\t\tif(((i+1) % acc_steps == 0) or (i== args.report_every)):\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\tif args.debug:\n",
        "\t\t\t\tlogging.info(f'Batch ID:{i} Loss:{loss.data.item()}')\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif( (i % args.report_every == 0) and (i!=0)):\n",
        "\t\t\t\tcur_loss = eval(net,vocab,val_iter,criterion)\n",
        "\t\t\t\ttrain_loss = t_loss/s_loss\n",
        "\t\t\t\tt_loss = 0\n",
        "\t\t\t\ts_loss = 0\n",
        "\t\t\t\tif cur_loss < min_loss:\n",
        "\t\t\t\t\tcheckpp = 0\n",
        "\t\t\t\t\tmin_loss = cur_loss\n",
        "\t\t\t\t\tbest_path = net.save()\n",
        "\t\t\t\t\tlogging.info('Model Checkpoint Saved')\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcheckpp = checkpp+1\n",
        "\n",
        "\t\t\t\tlogging.info('Epoch:%2d Min_Val_Loss: %f Cur_Val_Loss: %f training loss: %f'\n",
        "\t\t\t\t\t\t% (epoch,min_loss,cur_loss,train_loss))\n",
        "\n",
        "\tt2 = time()\n",
        "\tlogging.info('Total Time:%f h'%((t2-t1)/3600))\n",
        "\n",
        "def test():\n",
        "\n",
        "\t# embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
        "\t# with open(args.word2id) as f:\n",
        "\t#     word2id = json.load(f)\n",
        "\t\n",
        "\tembed, word2id = None, None\n",
        "\tvocab = utils.Vocab(embed, word2id)\n",
        "\n",
        "\t#Loading Test File Names\n",
        "\twith open(\"/content/SummaRuNNer/data/test_files.txt\") as f:\n",
        "\t\tfile_names = f.readlines()\n",
        "\tfile_names = [x.strip() for x in file_names]\n",
        "\n",
        "\twith open(args.test_dir) as f:\n",
        "\t\texamples = [json.loads(line) for line in f]\n",
        "\ttest_dataset = utils.Dataset(examples)\n",
        "\n",
        "\ttest_iter = DataLoader(dataset=test_dataset,\n",
        "\t\t\t\t\t\t\tbatch_size=args.batch_size,\n",
        "\t\t\t\t\t\t\tshuffle=False)\n",
        "\tif use_gpu:\n",
        "\t\tcheckpoint = torch.load(args.load_dir)\n",
        "\telse:\n",
        "\t\tcheckpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
        "\n",
        "\t# checkpoint['args']['device'] saves the device used as train time\n",
        "\t# if at test time, we are using a CPU, we must override device to None\n",
        "\tif not use_gpu:\n",
        "\t\tcheckpoint['args'].device = None\n",
        "\tnet = getattr(models,checkpoint['args'].model)(checkpoint['args'])\n",
        "\tnet.load_state_dict(checkpoint['model'])\n",
        "\tif use_gpu:\n",
        "\t\tnet.cuda()\n",
        "\tnet.eval()\n",
        "\n",
        "\tdoc_num = len(test_dataset)\n",
        "\ttime_cost = 0\n",
        "\tfile_count = 0\n",
        "\tfor batch in tqdm(test_iter):\n",
        "\t\tinput_ids,attention_masks,targets,summaries,doc_lens  = vocab.make_features(batch)\n",
        "\t\tinput_ids,attention_masks,targets = Variable(input_ids),Variable(attention_masks), Variable(targets.float())\n",
        "\t\tt1 = time()\n",
        "\t\tif use_gpu:\n",
        "\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\tprobs = net(input_ids,attention_masks,doc_lens)\n",
        "\t\telse:\n",
        "\t\t\tprobs = net(input_ids,attention_masks,doc_lens)\n",
        "\t\tt2 = time()\n",
        "\t\ttime_cost += t2 - t1\n",
        "\t\tstart = 0\n",
        "\t\tfor doc_id,doc_len in enumerate(doc_lens):\n",
        "\t\t\tstop = start + doc_len\n",
        "\t\t\tprob = probs[:stop]\n",
        "\t\t\ttopk_elems = min(args.topk,doc_len)\n",
        "\t\t\t\n",
        "\t\t\tvalues, indices = prob.topk(topk_elems)\n",
        "\t\t\ttopk_values, topk_indices = [], []\n",
        "\t\t\t\n",
        "\t\t\t#Consider predictions with >0.5 prob score\n",
        "\t\t\tfor v, i in zip(values, indices):\n",
        "\t\t\t\tif v >= 0.5:\n",
        "\t\t\t\t\ttopk_values.append(v.cpu().data.numpy())\n",
        "\t\t\t\t\ttopk_indices.append(i.cpu().data.numpy())\n",
        "\n",
        "\t\t\t#These values should be >0.5\n",
        "\t\t\tif(len(topk_values)==0):\n",
        "\t\t\t\tprint(f\"No predictions with >=0.5 prob_score in file: [{file_names[file_count]}]\")\n",
        "\t\t\t\tprint(f\"Prob Scores: {values}\")\n",
        "\n",
        "\t\t\ttopk_indices.sort()\n",
        "\t\t\tdoc = batch['doc'][doc_id].split('\\n')[:doc_len]\n",
        "\t\t\thyp = [doc[index] for index in topk_indices]\n",
        "\t\t\tref = summaries[doc_id]\n",
        "\t\t\twith open(os.path.join(args.ref, file_names[file_count]), 'w') as f:\n",
        "\t\t\t\tf.write(ref)\n",
        "\t\t\twith open(os.path.join(args.hyp, file_names[file_count]), 'w') as f:\n",
        "\t\t\t\tf.write('\\n'.join(hyp))\n",
        "\t\t\tstart = stop\n",
        "\t\t\tfile_count = file_count + 1\n",
        "\n",
        "\t\tdel input_ids\n",
        "\t\tdel attention_masks\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\tlogging.info(f'Speed: {(doc_num / time_cost)} docs / s' )\n",
        "\n",
        "\n",
        "def predict(examples):\n",
        "\t# embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
        "\t# with open(args.word2id) as f:\n",
        "\t#     word2id = json.load(f)\n",
        "\t\t\n",
        "\tembed, word2id = None, None\n",
        "\tvocab = utils.Vocab(embed, word2id)\n",
        "\tpred_dataset = utils.Dataset(examples)\n",
        "\n",
        "\tpred_iter = DataLoader(dataset=pred_dataset,\n",
        "\t\t\t\t\t\t\tbatch_size=args.batch_size,\n",
        "\t\t\t\t\t\t\tshuffle=False)\n",
        "\tif use_gpu:\n",
        "\t\tcheckpoint = torch.load(args.load_dir)\n",
        "\telse:\n",
        "\t\tcheckpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
        "\n",
        "\t# checkpoint['args']['device'] saves the device used as train time\n",
        "\t# if at test time, we are using a CPU, we must override device to None\n",
        "\tif not use_gpu:\n",
        "\t\tcheckpoint['args'].device = None\n",
        "\tnet = getattr(models,checkpoint['args'].model)(checkpoint['args'])\n",
        "\tnet.load_state_dict(checkpoint['model'])\n",
        "\n",
        "\tif use_gpu:\n",
        "\t\tnet.cuda()\n",
        "\tnet.eval()\n",
        "\n",
        "\tdoc_num = len(pred_dataset)\n",
        "\ttime_cost = 0\n",
        "\tfile_id = 1\n",
        "\tfor batch in tqdm(pred_iter):\n",
        "\t\tinput_ids,attention_masks, doc_lens = vocab.make_predict_features(batch)\n",
        "\t\tt1 = time()\n",
        "\t\tif use_gpu:\n",
        "\t\t\tprobs = net(input_ids,attention_masks,doc_lens)\n",
        "\t\telse:\n",
        "\t\t\tinput_ids,attention_masks = Variable(input_ids),Variable(attention_masks)\n",
        "\t\t\tprobs = net(input_ids,attention_masks, doc_lens)\n",
        "\t\tt2 = time()\n",
        "\t\ttime_cost += t2 - t1\n",
        "\t\tstart = 0\n",
        "\t\tfor doc_id,doc_len in enumerate(doc_lens):\n",
        "\t\t\tstop = start + doc_len\n",
        "\t\t\tprob = probs[start:stop]\n",
        "\t\t\ttopk_elems = min(args.topk,doc_len)\n",
        "\t\t\t\n",
        "\t\t\tvalues, indices = prob.topk(topk_elems)\n",
        "\t\t\ttopk_values, topk_indices = [], []\n",
        "\t\t\t\n",
        "\t\t\t#Consider predictions with >0.5 prob score\n",
        "\t\t\tfor v, i in zip(values, indices):\n",
        "\t\t\t\tif v >= 0.5:\n",
        "\t\t\t\t\ttopk_values.append(v.cpu().data.numpy())\n",
        "\t\t\t\t\ttopk_indices.append(i.cpu().data.numpy())\n",
        "\n",
        "\t\t\t#These values should be >0.5\n",
        "\t\t\t#print(topk_values)\n",
        "\t\t\t\n",
        "\t\t\ttopk_indices.sort()\n",
        "\t\t\t\n",
        "\t\t\tdoc = batch[doc_id].split('. ')[:doc_len]\n",
        "\t\t\thyp = [doc[index] for index in topk_indices]\n",
        "\t\t\twith open(os.path.join(args.hyp,str(file_id)+'.txt'), 'w') as f:\n",
        "\t\t\t\tf.write('. '.join(hyp))\n",
        "\t\t\tstart = stop\n",
        "\t\t\tfile_id = file_id + 1\n",
        "\tlogging.info(f'Speed: {(doc_num / time_cost)} docs / s' )\n",
        "\n",
        "if __name__=='__main__':\n",
        "\tif args.test:\n",
        "\t\tlogging.info(\"TESTING\")\n",
        "\t\ttest()\n",
        "\telif args.predict:\n",
        "\t\tlogging.info(\"PREDICTING\")\n",
        "\t\twith open(args.filename) as file:\n",
        "\t\t\tbod = [file.read()]\n",
        "\t\tpredict(bod)\n",
        "\telse:\n",
        "\t\tlogging.info(\"TRAINING\")\n",
        "\t\ttrain()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rajdeep"
      ],
      "metadata": {
        "id": "cL6i1OD32GOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SummaRuNNer with BERT models/RNN_RNN.py\n",
        "# By Rajdeep\n",
        "%%writefile models/RNN_RNN.py\n",
        "\n",
        "from .BasicModule import BasicModule\n",
        "import subprocess as sp\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"pytorch_pretrained_bert.tokenization\").setLevel(logging.ERROR)\n",
        "\n",
        "HH = 256\n",
        "\n",
        "class RNN_RNN(BasicModule):\n",
        "\tdef __init__(self, args, embed=None):\n",
        "\t\tsuper(RNN_RNN, self).__init__(args)\n",
        "\t\t\n",
        "\t\tself.model_name = 'RNN_RNN'\n",
        "\t\tself.args = args\n",
        "\t\t\n",
        "\t\t# V = args.embed_num\n",
        "\t\t# D = args.embed_dim\n",
        "\t\t\n",
        "\t\tH = args.hidden_size\n",
        "\t\tS = args.seg_num\n",
        "\t\tP_V = args.pos_num \n",
        "\t\tP_D = args.pos_dim\n",
        "\t\tself.abs_pos_embed = nn.Embedding(P_V, P_D)\n",
        "\t\tself.rel_pos_embed = nn.Embedding(S, P_D)\n",
        "\t\t\n",
        "\t\t# self.embed = nn.Embedding(V,D,padding_idx=0)\n",
        "\t\t# if embed is not None:\n",
        "\t\t#     self.embed.weight.data.copy_(embed)\n",
        "\n",
        "\t\tself.bert_m = BertModel.from_pretrained('ProsusAI/finbert')\n",
        "\t\t# for name, param in list(self.bert_m.named_parameters())[:-66]:\n",
        "\t\t# \tparam.requires_grad = False\n",
        "\n",
        "\t\tself.sent_RNN = nn.GRU(\n",
        "\t\t\t\t\t\tinput_size = 768,\n",
        "\t\t\t\t\t\thidden_size = HH,\n",
        "\t\t\t\t\t\tbatch_first = True,\n",
        "\t\t\t\t\t\tbidirectional = True\n",
        "\t\t\t\t\t\t)\n",
        "\t\tself.fc = nn.Linear(2*HH, 2*HH)\n",
        "\n",
        "\t\t# Parameters of Classification Layer\n",
        "\t\tself.content = nn.Linear(2*HH, 1, bias=False)\n",
        "\t\tself.salience = nn.Bilinear(2*HH, 2*HH, 1, bias=False)\n",
        "\t\tself.novelty = nn.Bilinear(2*HH, 2*HH, 1, bias=False)\n",
        "\t\tself.abs_pos = nn.Linear(P_D, 1, bias=False)\n",
        "\t\tself.rel_pos = nn.Linear(P_D, 1, bias=False)\n",
        "\t\tself.bias = nn.Parameter(torch.FloatTensor(1).uniform_(-0.1, 0.1))\n",
        "\n",
        "\tdef max_pool1d(self, x, seq_lens):\n",
        "\t\t# x:[N, L, O_in]\n",
        "\t\tout = []\n",
        "\t\tfor index,t in enumerate(x):\n",
        "\t\t\tt = t[:seq_lens[index],:]\n",
        "\t\t\tt = torch.t(t).unsqueeze(0)\n",
        "\t\t\tout.append(F.max_pool1d(t,t.size(2)))\n",
        "\n",
        "\t\tout = torch.cat(out).squeeze(2)\n",
        "\t\treturn out\n",
        "\n",
        "\tdef avg_pool1d(self, x, seq_lens):\n",
        "\t\t# x:[N, L, O_in]\n",
        "\t\tout = []\n",
        "\t\tfor index,t in enumerate(x):\n",
        "\t\t\tt = t[:seq_lens[index],:]\n",
        "\t\t\tt = torch.t(t).unsqueeze(0)\n",
        "\t\t\tout.append(F.avg_pool1d(t,t.size(2)))\n",
        "\n",
        "\t\tout = torch.cat(out).squeeze(2)\n",
        "\t\treturn out\n",
        "\n",
        "\tdef forward(self, input_ids, attention_masks, doc_lens):\n",
        "\t\t# word level GRU\n",
        "\t\t# H = self.args.hidden_size\n",
        "\t\t\n",
        "\t\toutputs = self.bert_m(input_ids=input_ids, attention_mask=attention_masks)\n",
        "\t\t\n",
        "\t\t# hidden representation of last layer \n",
        "\t\ttoken_vecs = outputs.last_hidden_state\t\t\n",
        "\t\t# dimension : [N, max_len_sent, 768] N: no of sentences\n",
        "\t\t\n",
        "\t\tk = 0\n",
        "\t\tfor i in token_vecs:\n",
        "\t\t\t# cls embedding\n",
        "\t\t\tsentence_embedding = i[0]\n",
        "\t\t\tsen = sentence_embedding.unsqueeze(0)\n",
        "\t\t\tif(k == 0):\t\t\t\t\n",
        "\t\t\t\temb = sen\n",
        "\t\t\t\tk = k + 1\n",
        "\t\t\telse:\n",
        "\t\t\t\temb = torch.cat((emb, sen), 0)\n",
        "\n",
        "\t\ttorch.cuda.empty_cache()\t\t\n",
        "\t\t# make sent features (pad with zeros)\n",
        "\t\tx = self.pad_doc(emb, doc_lens)\n",
        "\t\t\n",
        "\t\t# sent level GRU\n",
        "\t\tsent_out = self.sent_RNN(x)[0]\t\t\t\t\t\t\t\t\t\t# (B, max_doc_len, 2*H)\n",
        "\t\tdocs = self.max_pool1d(sent_out, doc_lens)\t\t\t\t\t\t\t# (B, 2*H)\n",
        "\t\t\n",
        "\t\tdel emb\t\t\n",
        "\t\tdel input_ids\n",
        "\t\tdel attention_masks\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\t\t\n",
        "\t\tprobs = []\t\t\n",
        "\t\tfor index, doc_len in enumerate(doc_lens):\n",
        "\t\t\tvalid_hidden = sent_out[index,:doc_len,:]\t\t\t\t\t\t# (doc_len, 2*H)\n",
        "\t\t\tdoc = F.tanh(self.fc(docs[index])).unsqueeze(0)\n",
        "\t\t\ts = Variable(torch.zeros(1,2*HH))\n",
        "\t\t\tif self.args.device is not None:\n",
        "\t\t\t\ts = s.cuda()\n",
        "\t\t\tfor position, h in enumerate(valid_hidden):\n",
        "\t\t\t\th = h.view(1, -1)\t\t\t\t\t\t\t\t\t\t\t# (1, 2*H)\n",
        "\t\t\t\t# get position embeddings\n",
        "\t\t\t\tabs_index = Variable(torch.LongTensor([[position]]))\n",
        "\t\t\t\tif self.args.device is not None:\n",
        "\t\t\t\t\tabs_index = abs_index.cuda()\n",
        "\t\t\t\tabs_features = self.abs_pos_embed(abs_index).squeeze(0)\n",
        "\n",
        "\t\t\t\trel_index = int(round((position + 1) * 9.0 / doc_len))\n",
        "\t\t\t\trel_index = Variable(torch.LongTensor([[rel_index]]))\n",
        "\t\t\t\tif self.args.device is not None:\n",
        "\t\t\t\t\trel_index = rel_index.cuda()\n",
        "\t\t\t\trel_features = self.rel_pos_embed(rel_index).squeeze(0)\n",
        "\n",
        "\t\t\t\t# classification layer\n",
        "\t\t\t\tcontent = self.content(h)\n",
        "\t\t\t\tsalience = self.salience(h,doc)\n",
        "\t\t\t\tnovelty = -1 * self.novelty(h,F.tanh(s))\n",
        "\t\t\t\tabs_p = self.abs_pos(abs_features)\n",
        "\t\t\t\trel_p = self.rel_pos(rel_features)\n",
        "\t\t\t\tprob = F.sigmoid(content + salience + novelty + abs_p + rel_p + self.bias)\n",
        "\t\t\t\ts = s + torch.mm(prob,h)\n",
        "\t\t\t\tprobs.append(prob)\n",
        "\t\t\n",
        "\t\tdel sent_out\n",
        "\t\tdel docs\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\t\t\n",
        "\t\treturn torch.cat(probs).squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8qjf-Ezfc0B",
        "outputId": "ea629d24-ee88-4c52-cfcf-2ad28d9f1f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting models/RNN_RNN.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SummaRuNNer with BERT utils/Vocab.py\n",
        "# By Rajdeep\n",
        "%%writefile utils/Vocab.py\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"pytorch_pretrained_bert.tokenization\").setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "class Vocab():\n",
        "\tdef __init__(self, embed, word2id):\n",
        "\t\tself.embed = embed\n",
        "\t\tself.word2id = word2id\n",
        "\t\t# self.id2word = {v:k for k,v in word2id.items()}\n",
        "\t\t# assert len(self.word2id) == len(self.id2word)\n",
        "\t\t# self.PAD_IDX = 0\n",
        "\t\t# self.UNK_IDX = 1\n",
        "\t\t# self.PAD_TOKEN = 'PAD_TOKEN'\n",
        "\t\t# self.UNK_TOKEN = 'UNK_TOKEN'\n",
        "\n",
        "\t# def __len__(self):\n",
        "\t#     return len(word2id)\n",
        "\n",
        "\t# def i2w(self,idx):\n",
        "\t#     return self.id2word[idx]\n",
        "\t# def w2i(self,w):\n",
        "\t#     if w in self.word2id:\n",
        "\t#         return self.word2id[w]\n",
        "\t#     else:\n",
        "\t#         return self.UNK_IDX\n",
        "\n",
        "\tdef make_features(self, batch, sent_trunc=50, doc_trunc=800, split_token='\\n'):\n",
        "\t\tsents_list, targets, doc_lens = [], [], []\n",
        "\t\t\n",
        "\t\t# trunc document\n",
        "\t\tfor doc, label in zip(batch['doc'], batch['labels']):\n",
        "\t\t\tsents = doc.split(split_token)\n",
        "\t\t\tlabels = label.split(split_token)\n",
        "\t\t\tlabels = [int(l) for l in labels]\n",
        "\t\t\tmax_sent_num = min(doc_trunc, len(sents))\n",
        "\t\t\tsents = sents[:max_sent_num]\n",
        "\t\t\tlabels = labels[:max_sent_num]\n",
        "\t\t\tsents_list += sents\n",
        "\t\t\ttargets += labels\n",
        "\t\t\tdoc_lens.append(len(sents))\n",
        "\t\t\n",
        "\t\t# # trunc or pad sent\n",
        "\t\t# max_sent_len = 0\n",
        "\t\t# batch_sents = []\n",
        "\t\t# for sent in sents_list:\n",
        "\t\t# \twords = sent.split()\n",
        "\t\t# \tif len(words) > sent_trunc:\n",
        "\t\t# \t\twords = words[:sent_trunc]\n",
        "\t\t# \tmax_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
        "\t\t# \tbatch_sents.append(words)\n",
        "\n",
        "\t\tinput_ids = []\n",
        "\t\tattention_masks = []\n",
        "\t\tfor sent in sents_list:\n",
        "\t\t\tencoded_dict = tokenizer.encode_plus(\n",
        "\t\t\t\ttext=sent,\n",
        "\t\t\t\ttext_pair=None,\n",
        "\t\t\t\tadd_special_tokens=True,\n",
        "\t\t\t\tpadding='max_length',\n",
        "\t\t\t\tmax_length=64,\n",
        "\t\t\t\ttruncation='longest_first',\n",
        "\t\t\t\treturn_token_type_ids=True,\n",
        "\t\t\t\treturn_tensors=\"pt\"\n",
        "\t\t\t\t)\t\t\t\n",
        "\t\t\tinput_ids.append(encoded_dict['input_ids'])\n",
        "\t\t\tattention_masks.append(encoded_dict['attention_mask'])\n",
        "\t\t\t\n",
        "\t\tinput_ids = torch.cat(input_ids, dim=0)\n",
        "\t\tattention_masks = torch.cat(attention_masks, dim=0)\n",
        "\t\ttargets = torch.LongTensor(targets)\n",
        "\t\tsummaries = batch['summaries']\n",
        "\n",
        "\t\treturn input_ids, attention_masks, targets, summaries, doc_lens\n",
        "\n",
        "\t\n",
        "\tdef make_predict_features(self, batch, sent_trunc=50, doc_trunc=800, split_token='. '):\n",
        "\t\tsents_list, doc_lens = [], []\n",
        "\t\tfor doc in batch:\n",
        "\t\t\tsents = doc.split(split_token)\n",
        "\t\t\tmax_sent_num = min(doc_trunc, len(sents))\n",
        "\t\t\tsents = sents[:max_sent_num]\n",
        "\t\t\tsents_list += sents\n",
        "\t\t\tdoc_lens.append(len(sents))\n",
        "\n",
        "\t\t# # trunc or pad sent\n",
        "\t\t# max_sent_len = 0\n",
        "\t\t# batch_sents = []\n",
        "\t\t# for sent in sents_list:\n",
        "\t\t# \twords = sent.split()\n",
        "\t\t# \tif len(words) > sent_trunc:\n",
        "\t\t# \t\twords = words[:sent_trunc]\n",
        "\t\t# \tmax_sent_len = len(words) if len(words) > max_sent_len else max_sent_len\n",
        "\t\t# \tbatch_sents.append(words)\n",
        "\n",
        "\t\t# features = []\n",
        "\t\t# for sent in batch_sents:\n",
        "\t\t#     feature = [self.w2i(w) for w in sent] + [self.PAD_IDX for _ in range(max_sent_len-len(sent))]\n",
        "\t\t#     features.append(feature)\n",
        "\t\t# features = torch.LongTensor(features)\n",
        "\n",
        "\t\tinput_ids = []\n",
        "\t\tattention_masks = []\n",
        "\t\tfor sent in sents_list:\n",
        "\t\t\tencoded_dict = tokenizer.encode_plus(\n",
        "\t\t\t\ttext=sent,\n",
        "\t\t\t\ttext_pair=None,\n",
        "\t\t\t\tadd_special_tokens=True,\n",
        "\t\t\t\tpadding='max_length',\n",
        "\t\t\t\tmax_length=64,\n",
        "\t\t\t\ttruncation='longest_first',\n",
        "\t\t\t\treturn_token_type_ids=True,\n",
        "\t\t\t\treturn_tensors=\"pt\"\n",
        "\t\t\t\t)\t\t\t\n",
        "\t\t\tinput_ids.append(encoded_dict['input_ids'])\n",
        "\t\t\tattention_masks.append(encoded_dict['attention_mask'])\n",
        "\t\t\t\n",
        "\t\tinput_ids = torch.cat(input_ids, dim=0)\n",
        "\t\tattention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\t\treturn  input_ids, attention_masks, doc_lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUfCZ3iLesXR",
        "outputId": "3b9e1be4-d784-44ab-cda9-5d4e8264ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils/Vocab.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SummaRuNNer with BERT main.py\n",
        "# By Rajdeep\n",
        "%%writefile main.py\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import subprocess as sp\n",
        "import os\n",
        "import json\n",
        "import models\n",
        "import utils\n",
        "import argparse,random,logging,numpy,os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn.utils import clip_grad_norm\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"pytorch_pretrained_bert.tokenization\").setLevel(logging.ERROR)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s [INFO] %(message)s')\n",
        "parser = argparse.ArgumentParser(description='extractive summary')\n",
        "# model\n",
        "parser.add_argument('-save_dir',type=str,default='checkpoints/')\n",
        "# parser.add_argument('-embed_dim',type=int,default=100)\n",
        "# parser.add_argument('-embed_num',type=int,default=100)\n",
        "parser.add_argument('-pos_dim',type=int,default=100)\n",
        "parser.add_argument('-pos_num',type=int,default=300)\n",
        "parser.add_argument('-seg_num',type=int,default=10)\n",
        "parser.add_argument('-kernel_num',type=int,default=100)\n",
        "parser.add_argument('-kernel_sizes',type=str,default='3,4,5')\n",
        "parser.add_argument('-model',type=str,default='RNN_RNN')\n",
        "parser.add_argument('-hidden_size',type=int,default=200)\n",
        "# train\n",
        "parser.add_argument('-lr',type=float,default=2e-5)\n",
        "parser.add_argument('-batch_size',type=int,default=16)\n",
        "parser.add_argument('-epochs',type=int,default=5)\n",
        "parser.add_argument('-seed',type=int,default=42)\n",
        "parser.add_argument('-train_dir',type=str,default='data/train.json')\n",
        "parser.add_argument('-val_dir',type=str,default='data/val.json')\n",
        "parser.add_argument('-embedding',type=str,default='data/embedding.npz')\n",
        "parser.add_argument('-word2id',type=str,default='data/word2id.json')\n",
        "parser.add_argument('-report_every',type=int,default=16)\n",
        "# parser.add_argument('-seq_trunc',type=int,default=50)\n",
        "parser.add_argument('-max_norm',type=float,default=1.0)\n",
        "# test\n",
        "parser.add_argument('-load_dir',type=str,default='checkpoints/RNN_RNN_seed_42.pt')\n",
        "parser.add_argument('-test_dir',type=str,default='data/test.json')\n",
        "parser.add_argument('-ref',type=str,default='outputs/ref')\n",
        "parser.add_argument('-hyp',type=str,default='outputs/hyp')\n",
        "parser.add_argument('-filename',type=str,default='x.txt') # TextFile to be summarized\n",
        "parser.add_argument('-topk',type=int,default=8)\n",
        "# device\n",
        "parser.add_argument('-device',type=int)\n",
        "# option\n",
        "parser.add_argument('-test',action='store_true')\n",
        "parser.add_argument('-debug',action='store_true')\n",
        "parser.add_argument('-predict',action='store_true')\n",
        "args = parser.parse_args()\n",
        "use_gpu = args.device is not None\n",
        "\n",
        "if torch.cuda.is_available() and not use_gpu:\n",
        "\tprint(\"WARNING: You have a CUDA device, should run with -device 0\")\n",
        "\n",
        "# set cuda device and seed\n",
        "if use_gpu:\n",
        "\ttorch.cuda.set_device(args.device)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "random.seed(args.seed)\n",
        "numpy.random.seed(args.seed)\n",
        "\n",
        "\n",
        "def eval(net, vocab, data_iter, criterion):\n",
        "\tnet.eval()\n",
        "\twith torch.no_grad():\t\t\n",
        "\t\ttotal_loss = 0\n",
        "\t\tbatch_num = 0\n",
        "\t\tfor batch in data_iter:\n",
        "\t\t\tinput_ids, attention_masks, targets, _, doc_lens = vocab.make_features(batch)\n",
        "\t\t\tinput_ids, attention_masks, targets = Variable(input_ids), Variable(attention_masks), Variable(targets.float())\n",
        "\t\t\tif use_gpu:\t\t\t\t\n",
        "\t\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\t\ttargets = targets.cuda()\n",
        "\t\t\tprobs = net(input_ids, attention_masks, doc_lens)\n",
        "\t\t\tloss = criterion(probs, targets)\n",
        "\t\t\ttotal_loss += loss.item()\n",
        "\t\t\tbatch_num += 1\n",
        "\t\tloss = total_loss / batch_num\n",
        "\t\tdel targets\n",
        "\t\tdel input_ids\n",
        "\t\tdel attention_masks\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\t\tnet.train()\n",
        "\treturn loss\n",
        "\n",
        "\n",
        "def train():\n",
        "\tlogging.info('Loading vocab, train and val dataset. Wait a second, please')\n",
        "\tearly_stopping = 3\n",
        "\t\n",
        "\t# embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
        "\t# with open(args.word2id) as f:\n",
        "\t#     word2id = json.load(f)\n",
        "\t\n",
        "\tembed, word2id = None, None\n",
        "\tvocab = utils.Vocab(embed, word2id)\n",
        "\n",
        "\twith open(args.train_dir) as f:\n",
        "\t\texamples = [json.loads(line) for line in f]\n",
        "\ttrain_dataset = utils.Dataset(examples)\n",
        "\n",
        "\twith open(args.val_dir) as f:\n",
        "\t\texamples = [json.loads(line) for line in f]\n",
        "\tval_dataset = utils.Dataset(examples)\n",
        "\n",
        "\t# update args\n",
        "\targs.kernel_sizes = [int(ks) for ks in args.kernel_sizes.split(',')]\n",
        "\t\n",
        "\t# args.embed_num = embed.size(0)\n",
        "\t# args.embed_dim = embed.size(1)\t\n",
        "\t# args.embed_num = None\n",
        "\t# args.embed_dim = None\t\n",
        "\n",
        "\tacc_steps = 2\n",
        "\t\n",
        "\t# build model\n",
        "\tnet = getattr(models, args.model)(args, embed)\n",
        "\tif use_gpu:\n",
        "\t\tnet.cuda()\n",
        "\t\n",
        "\t# load dataset\n",
        "\ttrain_iter = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "\tval_iter = DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\t\n",
        "\t# loss function\n",
        "\tcriterion = nn.BCELoss()\n",
        "\t\n",
        "\t# model info\n",
        "\t# print(net)\t\n",
        "\tparams = sum(p.numel() for p in list(net.parameters())) / 1e6\n",
        "\tprint('#Params: %.1fM' % (params))\n",
        "\n",
        "\tmin_loss = float('inf')\n",
        "\toptimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
        "\tnet.train()\n",
        "\n",
        "\tt1 = time()\n",
        "\tcheckpp = 0\n",
        "\tfor epoch in tqdm(range(1, args.epochs+1)):\n",
        "\t\tlogging.info(f\"\\nEpoch: {epoch}\")\n",
        "\t\tif(checkpp == early_stopping):\n",
        "\t\t\tbreak\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tt_loss = 0\n",
        "\t\ts_loss = 0\n",
        "\t\tfor i,batch in enumerate(train_iter):\n",
        "\t\t\tinput_ids, attention_masks, targets, _, doc_lens = vocab.make_features(batch)\n",
        "\t\t\tinput_ids, attention_masks, targets = Variable(input_ids), Variable(attention_masks), Variable(targets.float())\n",
        "\t\t\tif use_gpu:\n",
        "\t\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\t\ttargets = targets.cuda()\n",
        "\t\t\t   \n",
        "\t\t\tprobs = net(input_ids, attention_masks, doc_lens)\n",
        "\t\t\tloss = criterion(probs, targets)\t\t\t\n",
        "\t\t\tt_loss = t_loss + loss.item()\n",
        "\t\t\tloss = loss / acc_steps\n",
        "\t\t\ts_loss = s_loss + 1\n",
        "\t\t\tloss.backward()\n",
        "\t\t\tclip_grad_norm(net.parameters(), args.max_norm)\n",
        "\t\t\tif (i+1) % acc_steps == 0:\n",
        "\t\t\t\toptimizer.step()\n",
        "\t\t\t\toptimizer.zero_grad()\n",
        "\t\t\tif args.debug:\n",
        "\t\t\t\tlogging.info(f'Batch ID:{i} Loss:{loss.data.item()}')\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif (i+1) % args.report_every == 0:\n",
        "\t\t\t\tcur_loss = eval(net, vocab, val_iter, criterion)\n",
        "\t\t\t\ttrain_loss = t_loss/s_loss\n",
        "\t\t\t\tt_loss = 0\n",
        "\t\t\t\ts_loss = 0\n",
        "\t\t\t\tif cur_loss < min_loss:\n",
        "\t\t\t\t\tcheckpp = 0\n",
        "\t\t\t\t\tmin_loss = cur_loss\n",
        "\t\t\t\t\tbest_path = net.save()\n",
        "\t\t\t\t\tlogging.info('Model Checkpoint Saved')\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcheckpp = checkpp+1\n",
        "\t\t\t\tlogging.info(f'Epoch:{epoch} Min_Val_Loss: {min_loss} Cur_Val_Loss: {cur_loss} training loss: {train_loss}')\n",
        "\n",
        "\tt2 = time()\n",
        "\tlogging.info('Total Time:%f h'%((t2-t1)/3600))\n",
        "\n",
        "\n",
        "def test():\n",
        "\t# embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
        "\t# with open(args.word2id) as f:\n",
        "\t#     word2id = json.load(f)\n",
        "\t\n",
        "\tembed, word2id = None, None\n",
        "\tvocab = utils.Vocab(embed, word2id)\n",
        "\n",
        "\t#Loading Test File Names\n",
        "\twith open(\"data/test_files.txt\") as f:\n",
        "\t\tfile_names = f.readlines()\n",
        "\tfile_names = [x.strip() for x in file_names]\n",
        "\n",
        "\twith open(args.test_dir) as f:\n",
        "\t\texamples = [json.loads(line) for line in f]\n",
        "\ttest_dataset = utils.Dataset(examples)\n",
        "\n",
        "\ttest_iter = DataLoader(dataset=test_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\tif use_gpu:\n",
        "\t\tcheckpoint = torch.load(args.load_dir)\n",
        "\telse:\n",
        "\t\tcheckpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
        "\n",
        "\t# checkpoint['args']['device'] saves the device used as train time\n",
        "\t# if at test time, we are using a CPU, we must override device to None\n",
        "\tif not use_gpu:\n",
        "\t\tcheckpoint['args'].device = None\n",
        "\tnet = getattr(models, checkpoint['args'].model)(checkpoint['args'])\n",
        "\tnet.load_state_dict(checkpoint['model'])\n",
        "\tif use_gpu:\n",
        "\t\tnet.cuda()\n",
        "\tnet.eval()\n",
        "\n",
        "\tdoc_num = len(test_dataset)\n",
        "\ttime_cost = 0\n",
        "\tfile_count = 0\n",
        "\tfor batch in tqdm(test_iter):\n",
        "\t\tinput_ids, attention_masks, targets, summaries, doc_lens  = vocab.make_features(batch)\n",
        "\t\tinput_ids, attention_masks, targets = Variable(input_ids), Variable(attention_masks), Variable(targets.float())\n",
        "\t\tt1 = time()\n",
        "\t\tif use_gpu:\n",
        "\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\tprobs = net(input_ids, attention_masks, doc_lens)\n",
        "\t\telse:\n",
        "\t\t\tprobs = net(input_ids, attention_masks, doc_lens)\n",
        "\t\tt2 = time()\n",
        "\t\ttime_cost += t2 - t1\n",
        "\t\tstart = 0\n",
        "\t\tfor doc_id, doc_len in enumerate(doc_lens):\n",
        "\t\t\tstop = start + doc_len\n",
        "\t\t\tprob = probs[:stop]\n",
        "\t\t\ttopk_elems = min(args.topk, doc_len)\t\t\t\n",
        "\t\t\tvalues, indices = prob.topk(topk_elems)\n",
        "\t\t\ttopk_values, topk_indices = [], []\t\t\t\n",
        "\t\t\t#Consider predictions with >=0.5 prob score\n",
        "\t\t\tfor v, i in zip(values, indices):\n",
        "\t\t\t\tif v >= 0.5:\n",
        "\t\t\t\t\ttopk_values.append(v.cpu().data.numpy())\n",
        "\t\t\t\t\ttopk_indices.append(i.cpu().data.numpy())\n",
        "\t\t\t#These values should be >0.5\n",
        "\t\t\tif(len(topk_values) == 0):\n",
        "\t\t\t\tprint(f\"No predictions with >=0.5 prob_score in file: [{file_names[file_count]}]\")\n",
        "\t\t\t\tprint(f\"Prob Scores: {values}\")\n",
        "\n",
        "\t\t\ttopk_indices.sort()\n",
        "\t\t\tdoc = batch['doc'][doc_id].split('\\n')[:doc_len]\n",
        "\t\t\thyp = [doc[index] for index in topk_indices]\n",
        "\t\t\tref = summaries[doc_id]\n",
        "\t\t\tif not os.path.isdir(args.ref):\n",
        "\t\t\t\tos.makedirs(args.ref)\n",
        "\t\t\twith open(os.path.join(args.ref, file_names[file_count]), 'w') as f:\n",
        "\t\t\t\tf.write(ref)\n",
        "\t\t\tif not os.path.isdir(args.hyp):\n",
        "\t\t\t\tos.makedirs(args.hyp)\n",
        "\t\t\twith open(os.path.join(args.hyp, file_names[file_count]), 'w') as f:\n",
        "\t\t\t\tf.write('\\n'.join(hyp))\n",
        "\t\t\tstart = stop\n",
        "\t\t\tfile_count = file_count + 1\n",
        "\n",
        "\t\tdel input_ids\n",
        "\t\tdel attention_masks\n",
        "\t\ttorch.cuda.empty_cache()\n",
        "\tlogging.info(f'Speed: {(doc_num / time_cost)} docs / s' )\n",
        "\n",
        "\n",
        "def predict(examples):\n",
        "\t# embed = torch.Tensor(np.load(args.embedding)['embedding'])\n",
        "\t# with open(args.word2id) as f:\n",
        "\t#     word2id = json.load(f)\n",
        "\t\t\n",
        "\tembed, word2id = None, None\n",
        "\tvocab = utils.Vocab(embed, word2id)\n",
        "\t\n",
        "\tpred_dataset = utils.Dataset(examples)\n",
        "\tpred_iter = DataLoader(dataset=pred_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\tif use_gpu:\n",
        "\t\tcheckpoint = torch.load(args.load_dir)\n",
        "\telse:\n",
        "\t\tcheckpoint = torch.load(args.load_dir, map_location=lambda storage, loc: storage)\n",
        "\n",
        "\t# checkpoint['args']['device'] saves the device used as train time\n",
        "\t# if at test time, we are using a CPU, we must override device to None\n",
        "\tif not use_gpu:\n",
        "\t\tcheckpoint['args'].device = None\n",
        "\tnet = getattr(models,checkpoint['args'].model)(checkpoint['args'])\n",
        "\tnet.load_state_dict(checkpoint['model'])\n",
        "\n",
        "\tif use_gpu:\n",
        "\t\tnet.cuda()\n",
        "\tnet.eval()\n",
        "\n",
        "\tdoc_num = len(pred_dataset)\n",
        "\ttime_cost = 0\n",
        "\tfile_id = 1\n",
        "\tfor batch in tqdm(pred_iter):\n",
        "\t\tinput_ids, attention_masks, doc_lens  = vocab.make_predict_features(batch)\n",
        "\t\tinput_ids, attention_masks = Variable(input_ids), Variable(attention_masks)\n",
        "\t\tt1 = time()\n",
        "\t\tif use_gpu:\n",
        "\t\t\tinput_ids = input_ids.cuda()\n",
        "\t\t\tattention_masks = attention_masks.cuda()\n",
        "\t\t\tprobs = net(input_ids, attention_masks, doc_lens)\n",
        "\t\telse:\n",
        "\t\t\tprobs = net(input_ids, attention_masks, doc_lens)\n",
        "\t\tt2 = time()\n",
        "\t\ttime_cost += t2 - t1\n",
        "\t\tstart = 0\n",
        "\t\tfor doc_id, doc_len in enumerate(doc_lens):\n",
        "\t\t\tstop = start + doc_len\n",
        "\t\t\tprob = probs[start:stop]\n",
        "\t\t\ttopk_elems = min(args.topk, doc_len)\t\t\t\n",
        "\t\t\tvalues, indices = prob.topk(topk_elems)\n",
        "\t\t\ttopk_values, topk_indices = [], []\t\t\t\n",
        "\t\t\t#Consider predictions with >=0.5 prob score\n",
        "\t\t\tfor v, i in zip(values, indices):\n",
        "\t\t\t\tif v >= 0.5:\n",
        "\t\t\t\t\ttopk_values.append(v.cpu().data.numpy())\n",
        "\t\t\t\t\ttopk_indices.append(i.cpu().data.numpy())\n",
        "\n",
        "\t\t\t#These values should be >0.5\n",
        "\t\t\t#print(topk_values)\n",
        "\t\t\t\n",
        "\t\t\ttopk_indices.sort()\t\t\t\n",
        "\t\t\tdoc = batch[doc_id].split('. ')[:doc_len]\n",
        "\t\t\thyp = [doc[index] for index in topk_indices]\n",
        "\t\t\tif not os.path.isdir(args.hyp):\n",
        "\t\t\t\tos.makedirs(args.hyp)\n",
        "\t\t\twith open(os.path.join(args.hyp, str(file_id) + '.txt'), 'w') as f:\n",
        "\t\t\t\tf.write('. '.join(hyp))\n",
        "\t\t\tstart = stop\n",
        "\t\t\tfile_id = file_id + 1\n",
        "\tlogging.info(f'Speed: {(doc_num / time_cost)} docs / s' )\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\tif args.test:\n",
        "\t\tlogging.info(\"TESTING\")\n",
        "\t\ttest()\n",
        "\telif args.predict:\n",
        "\t\tlogging.info(\"PREDICTING\")\n",
        "\t\twith open(args.filename) as file:\n",
        "\t\t\tbod = [file.read()]\n",
        "\t\tpredict(bod)\n",
        "\telse:\n",
        "\t\tlogging.info(\"TRAINING\")\n",
        "\t\ttrain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz6nqxz0hMug",
        "outputId": "6a585511-55a5-41fc-e10c-7f00ffdbc675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpF_bYSz0F_D"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5adRL_sL0HrO",
        "outputId": "4226a667-8086-4779-c18e-895bd797be11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-22 22:20:19,724 [INFO] TRAINING\n",
            "2022-05-22 22:20:19,725 [INFO] Loading vocab, train and val dataset. Wait a second, please\n",
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "#Params: 111.9M\n",
            "  0% 0/5 [00:00<?, ?it/s]2022-05-22 22:20:26,061 [INFO] \n",
            "Epoch: 1\n",
            "2022-05-22 22:21:03,305 [INFO] Model Checkpoint Saved\n",
            "2022-05-22 22:21:03,305 [INFO] Epoch:1 Min_Val_Loss: 0.2258691761701826 Cur_Val_Loss: 0.2258691761701826 training loss: 0.3719206308014691\n",
            "  0% 0/5 [01:09<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 368, in <module>\n",
            "    train()\n",
            "  File \"main.py\", line 184, in train\n",
            "    cur_loss = eval(net, vocab, val_iter, criterion)\n",
            "  File \"main.py\", line 90, in eval\n",
            "    probs = net(input_ids, attention_masks, doc_lens)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/SummaRuNNer/models/RNN_RNN.py\", line 136, in forward\n",
            "    salience = self.salience(h,doc)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 189, in forward\n",
            "    return F.bilinear(input1, input2, self.weight, self.bias)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python main.py -device 0 -batch_size 2 -epochs 5 -model RNN_RNN -seed 42 -save_dir checkpoints/SR_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKjzvea20W6E"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS0D0io_0XsU"
      },
      "outputs": [],
      "source": [
        "# Uncomment to remove previous pred. outputs\n",
        "# !rm /content/SummaRuNNer/outputs/hyp/*\n",
        "# !rm /content/SummaRuNNer/outputs/ref/*\n",
        "\n",
        "!python main.py -device 0 -batch_size 1 -test -load_dir checkpoints/SR_RNN_RNN_seed_1.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfyCmN8d0gxx"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFrETbyR0hoK"
      },
      "outputs": [],
      "source": [
        "# !python main.py -batch_size 1 -predict -filename x.txt -load_dir checkpoints/SR_RNN_RNN_seed_1.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRKV2pFzXxqT"
      },
      "source": [
        "# Data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17oeT19fWK8n"
      },
      "outputs": [],
      "source": [
        "# !git clone https://RajdeepMukherjee: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@github.com/rajdeep345/ECTSumm.git\n",
        "# !git clone https://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@github.com/abhinav-bohra/Long-Text-Summarization.git\n",
        "# ! cp -r /content/ECTSumm/data/reuters/sr/exp2/* /content/Long-Text-Summarization/data/reuters/summarunner/\n",
        "# %cd /content/SummaRuNNer/ECTSumm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNkKYIgKXfdk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ect_utils import *\n",
        "\n",
        "# Experiment 2\n",
        "# Doc - All lines with numerical/monetary figures/values that cover target summary sentences\n",
        "# Summ - All lines except REFINITIV that are covered by document sentences\n",
        "\n",
        "\n",
        "def getDocLines(fname):\n",
        "    doc_lines = get_DocLines(fname)\n",
        "    processed_lines = getProcessedLines(doc_lines)\n",
        "    assert len(doc_lines) == len(processed_lines)\n",
        "    num_lines = []\n",
        "    for i in range(len(processed_lines)):\n",
        "        if '[NUM]' in processed_lines[i]:\n",
        "            num_lines.append(doc_lines[i])\n",
        "    return num_lines\n",
        "\n",
        "\n",
        "def getSummLines(fname):\n",
        "    lines = get_SummLines(fname)\n",
        "    lines = [line for line in lines if 'REFINITIV IBES DATA' not in line]\n",
        "    return lines\n",
        "    \n",
        "\n",
        "def prepare_data(dataPath, out_path):\n",
        "    ect_path = f'{dataPath}/ects/'\n",
        "    summ_path = f'{dataPath}/gt_summaries/'\n",
        "    data = list()\n",
        "    for file in tqdm(os.listdir(ect_path)):\n",
        "        if file.endswith('.txt'):\n",
        "            doc_lines = getDocLines(f'{ect_path}{file}')\n",
        "            summ_lines = getSummLines(f'{summ_path}{file}')\n",
        "            d_lines, s_lines = [], []\n",
        "            labels = np.zeros(len(doc_lines))\n",
        "            for line in summ_lines:\n",
        "                summ_text = getPartiallyProcessedText(line)\n",
        "                if re.search(pattern6, summ_text):\n",
        "                    values_summ_line = re.findall(pattern6, summ_text)\n",
        "                    for i, text in enumerate(doc_lines):\n",
        "                        doc_text = getPartiallyProcessedText(text)\n",
        "                        values_doc_line = re.findall(pattern6, doc_text)\n",
        "                        if set(values_doc_line).issuperset(set(values_summ_line)):\n",
        "                            labels[i]=1\n",
        "                            d_lines.append(text)\n",
        "                            s_lines.append(line)\n",
        "                            \n",
        "            assert len(doc_lines) == len(labels)\n",
        "            #print(len(labels)-np.sum(labels))\n",
        "            data_point = {\"doc\": '\\n'.join(doc_lines), \"summaries\":'\\n'.join(summ_lines),\"labels\":'\\n'.join([str(int(l)) for l in labels]) }\n",
        "            data_str = json.dumps(data_point)\n",
        "            data.append(data_str)\n",
        "    \n",
        "    with open(out_path, mode='wt', encoding='utf-8') as myfile:\n",
        "        myfile.write('\\n'.join(data))\n",
        "        print(len(data))\n",
        "    \n",
        "    myfile.close()\n",
        "    \n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    print(f'\\n\\n{split} data')\n",
        "    prepare_data(f'/content/Long-Text-Summarization/data/reuters/exp2/{split}', f'/content/Long-Text-Summarization/data/reuters/summarunner/{split}.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ApSdHJCo9i1"
      },
      "source": [
        "# Update Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow0oEckuPtli"
      },
      "outputs": [],
      "source": [
        "!cp /content/SummaRuNNer/checkpoints/SR_RNN_RNN_seed_1.pt  /content/Long-Text-Summarization/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lw_w0WWhRlw"
      },
      "outputs": [],
      "source": [
        "%cd /content/Long-Text-Summarization\n",
        "!git add .\n",
        "!git status\n",
        "!git config --global user.email \"abhinavbohra@iitkgp.ac.in\"\n",
        "!git config --global user.name \"abhinav-bohra\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Fv_PNMko7Qd"
      },
      "outputs": [],
      "source": [
        "!git commit -m \"Added SummaRuNNer Model Checkpoint\"\n",
        "!git push https://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@github.com/abhinav-bohra/Long-Text-Summarization.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA_DEfFLpeAa"
      },
      "outputs": [],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr_ny0KuKb-X"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XRKV2pFzXxqT"
      ],
      "machine_shape": "hm",
      "name": "SummaRuNNer_w_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}